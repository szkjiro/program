{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/szkjiro/program/blob/main/PyAozora.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6df19b2-98b8-4afc-a3b6-e715520ca884",
      "metadata": {
        "id": "c6df19b2-98b8-4afc-a3b6-e715520ca884"
      },
      "source": [
        "# 自然言語処理をする\n",
        "\n",
        "ワードクラウドと呼ばれる，ツイッター（現X）などで使われる単語頻度を直感的に表示する手法にワードクラウドがあります．\n",
        "例：[国会議案データでワードクラウドを作ってみよう](https://www.mediatechnology.jp/entry/parliamentary-bills-database)\n",
        "\n",
        "このワードクラウドを作成するには，\n",
        "1. もとの文章を単語単位に分ける\n",
        "2. 各単語の頻度を集計する\n",
        "3. ワードクラウドに作成する\n",
        "\n",
        "というステップを踏みます．\n",
        "単語単位に分ける部分（形態素解析）は，自然言語処理技術としても触れます．\n",
        "\n",
        "この演習課題では，単に頻度集計の一例としてワードクラウドを体験することに集中します．\n",
        "\n",
        "統計処理としては単に集計するだけなのできわめて単純です．\n",
        "新しい技術，最近よく見かける技術だからと言って，基礎的なところに注目してみれば，最新の難解な技術が使われているわけではない一例です．\n",
        "\n",
        "## Pythonで形態素解析を使う\n",
        "\n",
        "最初に形態素解析ツールMeCab[参考：MeCabのサイト](https://taku910.github.io/mecab/)を使えるようにします．\n",
        "ワードクラウドで使うためのフォントもインストールしておきます．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79ee7445-5972-4d51-9f6d-981c697e0b8b",
      "metadata": {
        "id": "79ee7445-5972-4d51-9f6d-981c697e0b8b"
      },
      "outputs": [],
      "source": [
        "!apt-get -y install fonts-ipafont-gothic\n",
        "! pip install mecab-python3 unidic-lite"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f088bd55-9bdb-4608-aabb-45ec07c07b18",
      "metadata": {
        "id": "f088bd55-9bdb-4608-aabb-45ec07c07b18"
      },
      "source": [
        "次に形態素解析が実際にうまくできるか，簡単なサンプルで試します．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d4d4eb0-0ccf-47b4-ade9-97fd29f545e0",
      "metadata": {
        "id": "5d4d4eb0-0ccf-47b4-ade9-97fd29f545e0"
      },
      "outputs": [],
      "source": [
        "import MeCab\n",
        "print(MeCab.Tagger().parse(\"失敗に挑戦しないことが最大の失敗である\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f73c106-8f28-4c2e-926e-9c75fcaca7f3",
      "metadata": {
        "id": "1f73c106-8f28-4c2e-926e-9c75fcaca7f3"
      },
      "source": [
        "上の実行例でわかるように，形態素解析では入力データを単語単位に分割します．\n",
        "次の例では上の文を分かち書きだけにして表示しました．\n",
        "中学校国語の文法で，こうした単語の分割を学習した人もいるのではありませんか．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "c0fe533b-9a99-487a-84a6-8fe04ebe324d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0fe533b-9a99-487a-84a6-8fe04ebe324d",
        "outputId": "ca03a5b5-e010-439e-b6c5-0a9355df4639"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "失敗 に 挑戦 し ない こと が 最大 の 失敗 で ある \n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(MeCab.Tagger(\"-Owakati\").parse(\"失敗に挑戦しないことが最大の失敗である\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61b18d2e-44e6-4388-8a9a-f610dea49559",
      "metadata": {
        "id": "61b18d2e-44e6-4388-8a9a-f610dea49559"
      },
      "source": [
        "## 青空文庫からテキストファイルを取得する\n",
        "\n",
        "ここでは青空文庫から作品ファイルを取得してみます．\n",
        "以上の各例題が実行済みでないと，この先はうまく進まないので注意しましょう．\n",
        "以下の例題の実行が済んだら，\n",
        "みなさんも好みの作品のURLで置き換えて実行してみてください．\n",
        "\n",
        "ファイル取得用のURLは，[青空文庫](https://www.aozora.gr.jp)にて，作品を選択すると以下が表示されます．\n",
        "\n",
        ">［ファイルのダウンロード｜いますぐXHTML版で読む］\n",
        "\n",
        "この右側の「いますぐXHTML版で読む」を選択すれば，作品が表示されます．\n",
        "その作品のリンクをコピーして，以下のプログラムの所定の部分を置き換えてください．\n",
        "以下の例題で，この変更をするものは，以下の2つのプログラムだけです．\n",
        "\n",
        "まずは青空文庫からあなたのGoogle Colab環境にファイルをダウンロードします．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8e6028d-c7e8-441c-a7c6-3bf6cb5e0e7f",
      "metadata": {
        "id": "f8e6028d-c7e8-441c-a7c6-3bf6cb5e0e7f"
      },
      "outputs": [],
      "source": [
        "! wget https://www.aozora.gr.jp/cards/000042/files/1108_13798.html"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "24ea192f-9ad0-489b-8771-4ba47f6fe1da",
      "metadata": {
        "id": "24ea192f-9ad0-489b-8771-4ba47f6fe1da"
      },
      "source": [
        "次のプログラムでは上でダウンロードしたファイルを使えるようにします．\n",
        "そのために上のプログラムで取得するファイル名（各作品に対応）を変更した場合，以下でも同じファイル名に変更しておいてください．\n",
        "今回の課題で書き換えを行うのはここまでです．\n",
        "\n",
        "ダウンロードしたファイルはHTMLというウェブページ用の形式であるため，本文以外の情報（HTMLタグなど）を多く含みます．\n",
        "それらの情報は文章の分析に不要なので，BeautifulSoupというツールを用いて除去します．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b33c00f-27b9-4afb-acc0-c90a01bddfdc",
      "metadata": {
        "id": "9b33c00f-27b9-4afb-acc0-c90a01bddfdc"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "f = open('1108_13798.html', 'r', encoding='SJIS')\n",
        "html_file = f.read()\n",
        "f.close()\n",
        "# 代入結果の確認\n",
        "html_file\n",
        "# 本文のみにする\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "soup = BeautifulSoup(html_file, 'lxml')\n",
        "\n",
        "main_text = soup.find(\"div\", class_='main_text')\n",
        "\n",
        "#ルビが振ってあるのを削除\n",
        "for yomigana in main_text.find_all([\"rp\",\"h4\",\"rt\"]):\n",
        "  yomigana.decompose()\n",
        "\n",
        "bunko_text = [line.strip() for line in main_text.text.strip().splitlines()]\n",
        "\n",
        "print(bunko_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c98b71fd-47c0-47a0-a735-e0ff7e2c19e8",
      "metadata": {
        "id": "c98b71fd-47c0-47a0-a735-e0ff7e2c19e8"
      },
      "source": [
        "青空文庫では，他にも各作品を作成したボランティア情報など，作品そのものの分析に不要な情報も含みますが，ここでは処理を簡単に見せるため省略しています．\n",
        "\n",
        "## ワードクラウドの出力\n",
        "\n",
        "以下のプログラムは，ワードクラウドに出力する準備状況の確認に，すでに試した分かち書きにします．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc13619f-acff-4120-afe5-9c375122b2af",
      "metadata": {
        "id": "cc13619f-acff-4120-afe5-9c375122b2af"
      },
      "outputs": [],
      "source": [
        "bunko_text2=','.join(bunko_text)\n",
        "bunko_text3 = MeCab.Tagger(\"-Owakati\").parse(bunko_text2)\n",
        "print(bunko_text3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0106c820-bdf4-4131-af35-bb5e0b23a72c",
      "metadata": {
        "id": "0106c820-bdf4-4131-af35-bb5e0b23a72c"
      },
      "source": [
        "以下ではワードクラウドを出力するためのライブラリをインストールし，\n",
        "上で準備した文章を与えて出力しています．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f9ed689-6d6a-4423-a808-d43fe08dbc98",
      "metadata": {
        "id": "0f9ed689-6d6a-4423-a808-d43fe08dbc98"
      },
      "outputs": [],
      "source": [
        "!pip install wordcloud\n",
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "# 文字表示用フォント指定\n",
        "f_path = '/usr/share/fonts/opentype/ipafont-gothic/ipagp.ttf' #日本語フォントの取得\n",
        "wordcloud = WordCloud(background_color=\"white\", font_path=f_path, width=700, height=600)\n",
        "wordcloud.generate(bunko_text3)\n",
        "plt.figure(figsize=(12,10))\n",
        "plt.imshow(wordcloud)\n",
        "plt.axis(\"off\") #メモリの非表示\n",
        "# plt.show()\n",
        "# 以下のファイル名で保存されます．提出用はダウンロードして利用してください．\n",
        "plt.savefig(\"word_cloud1.png\")\n",
        "from google.colab import files\n",
        "files.download(\"word_cloud1.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "上の例では「は，の，に，を」を含めたすべての単語を集計しています．\n",
        "そのため，ワードクラウドにはそれらが一番頻出する単語として表示されました．\n",
        "次では名詞のみに絞ってワードクラウドを作成するための処理をしています．"
      ],
      "metadata": {
        "id": "K8dllwtiA9F5"
      },
      "id": "K8dllwtiA9F5"
    },
    {
      "cell_type": "code",
      "source": [
        "import MeCab\n",
        "# 取り出したい品詞\n",
        "select_conditions = ['名詞']\n",
        "# select_conditions = ['形容詞', '副詞']\n",
        "\n",
        "# 分かち書きオブジェクト\n",
        "tagger = MeCab.Tagger('')\n",
        "tagger.parse('')\n",
        "\n",
        "# 関数の定義\n",
        "# 指定した品詞を取り出し分かち書きの文を返す\n",
        "def wakati_text(text):\n",
        "    # 分けてノードごとにする\n",
        "    node = tagger.parseToNode(text)\n",
        "    terms = []\n",
        "\n",
        "    while node:\n",
        "        # 単語\n",
        "        term = node.surface\n",
        "        # 品詞\n",
        "        pos = node.feature.split(',')[0]\n",
        "        # もし品詞が条件と一致してたら\n",
        "        if pos in select_conditions:\n",
        "            terms.append(term)\n",
        "        node = node.next\n",
        "\n",
        "    # 連結する\n",
        "    text_result = ' '.join(terms)\n",
        "    return text_result\n",
        "\n",
        "bunko_text2=','.join(bunko_text)\n",
        "bunko_text3 = MeCab.Tagger(\"-Owakati\").parse(bunko_text2)\n",
        "bunko_text4 = wakati_text(bunko_text3)\n",
        "\n",
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "# 文字表示用フォント指定\n",
        "f_path = '/usr/share/fonts/opentype/ipafont-gothic/ipagp.ttf' #日本語フォントの取得\n",
        "wordcloud = WordCloud(background_color=\"white\", font_path=f_path, width=700, height=600)\n",
        "wordcloud.generate(bunko_text4)\n",
        "plt.figure(figsize=(12,10))\n",
        "plt.imshow(wordcloud)\n",
        "plt.axis(\"off\") #メモリの非表示\n",
        "# plt.show()\n",
        "# 以下のファイル名で保存されます．提出用はダウンロードして利用してください．\n",
        "# ファイル名を実行ごとに変更すれば別々のファイルに保存できます\n",
        "# 拡張子は変更しないでください\n",
        "plt.savefig(\"word_cloud1.png\")\n",
        "from google.colab import files\n",
        "files.download(\"word_cloud1.png\")"
      ],
      "metadata": {
        "id": "k3EwmgfjBPgG"
      },
      "id": "k3EwmgfjBPgG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "各自で分析したワードクラウドの提出について．この演習ファイルを利用している授業によっては，自身で分析させたワードクラウドの表示結果ファイルを提出するよう指示があると思います．\n",
        "該当する人は，Google Colabのフォルダ内に画像ファイル（拡張子png）が出来上がっているので，そのファイルを各自でダウンロードの上，提出してください．"
      ],
      "metadata": {
        "id": "VaCjzU11lg65"
      },
      "id": "VaCjzU11lg65"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}